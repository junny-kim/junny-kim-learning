{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Reinforcement Learning (DQN) tutorial - TTbot\n",
    "======================================\n",
    "\n",
    "<img src=\"https://www.naverlabs.com/naverlabs_/story/201803/1520480681892_TTbot_%ED%9D%B0%EB%B0%B0%EA%B2%BD.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 93,
>>>>>>> 565ceb290df3e12e4b4324c5d4f84c497634a222
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TTBot Simulator\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulator = {\"width\":31, \"height\":31, \"center\":15, \"resol\":3}\n",
    "map_param = {\"width\":100, \"height\":100, \"center\":50, \"resol\":1, \"scale\":5, \"Map.data.obstacle\": 200, \"Map.data.ball\": 1}\n",
    "# walls_samples = [[1.2,2.0],[1.4,2.0],[1.6,2.0],[1.2,4.0],[1.4,4.0],[1.6,4.0],[1.2,-2.0],[1.4,-2.0],[1.6,-2.0],[1.2,-4.0],[1.4,-4.0],[1.6,-4.0]]\n",
    "walls_samples = [[1.5,-30.0],[30.4,0.7],[-30.4,-0.7]]\n",
    "\n",
    "camera_fov = 120\n",
    "ball_blind_ratio = 1/np.tan(camera_fov/2*np.pi/180)\n",
    "ball_blind_bias = 5\n",
    "\n",
    "reward_region_x = 2\n",
    "reward_region_y = [0,1,2,3]\n",
    "\n",
    "trans_scale = int(simulator[\"resol\"]/map_param[\"resol\"])\n",
    "rot_scale = 20\n",
    "\n",
    "debug_scale = 10\n",
    "debug_scale_gray = 3\n",
    "\n",
    "max_iter = 99\n",
    "\n",
    "class TTbotGym:\n",
    "    def __init__(self, debug_flag=False, mlp_flag=False, test_flag=False, state_blink=True, state_inaccurate=True):\n",
    "        self.frame = np.zeros((simulator[\"height\"],simulator[\"width\"],1), np.uint8)\n",
    "        self.frame_gray = np.zeros((simulator[\"height\"]*debug_scale_gray,simulator[\"width\"]*debug_scale_gray,1), np.uint8)\n",
    "        self.balls = []\n",
    "        self.balls_prev = []\n",
    "        self.obstacles = []\n",
    "        self.episode_rewards = []\n",
    "        self.score = 0\n",
    "        self.iter = 0\n",
    "        self.done = False\n",
    "\n",
    "        self.write_flag = False\n",
    "        self.debug_flag = debug_flag\n",
    "        self.mlp_flag = mlp_flag\n",
    "        self.test_flag = test_flag\n",
    "        self.ball_inscreen_flag = 0\n",
    "        self.state_blink = state_blink\n",
    "        self.state_inaccurate = state_inaccurate\n",
    "\n",
    "        ############################################################\n",
    "        # Flag Setups\n",
    "        # debug_flag : Display colored map for demonstration\n",
    "        # mlp_flag : If true, step() returns small 31x31 gray scale image for Multi Layer Perception.\n",
    "        #            If false, step() returns 93x93 gray scale image for Convolutional Neural Network\n",
    "        # test_flag : Whether it is training phase or test phase. During the test phase, the simulator saves every demonstration in form of video\n",
    "        # write_flag : If true, it records videos\n",
    "        # state_blink : Simulate target's detection error\n",
    "        # state_inaccurate : Simulate target's position estimation error\n",
    "        ############################################################\n",
    "\n",
    "        ## DQN parameters\n",
    "        if self.mlp_flag:\n",
    "            self.observation_space = self.frame.copy()\n",
    "        else:\n",
    "            self.observation_space = self.frame_gray.copy()\n",
    "\n",
    "        self.action_space = np.array(range(10))\n",
    "\n",
    "\n",
    "        # self.reset(max_balls=20, max_walls=3)\n",
    "        return\n",
    "\n",
    "    def reset(self, max_balls=20, max_walls=2):\n",
    "        self.frame = np.zeros((simulator[\"height\"],simulator[\"width\"],1), np.uint8)\n",
    "        self.frame_gray = np.zeros((simulator[\"height\"]*debug_scale_gray,simulator[\"width\"]*debug_scale_gray,1), np.uint8)\n",
    "        self.balls = []\n",
    "        self.balls_prev = []\n",
    "        self.obstacles = []\n",
    "        self.score = 0\n",
    "        self.iter = 0\n",
    "        self.done = False\n",
    "        self.write_flag = False\n",
    "        self.ball_inscreen_flag = 0\n",
    "\n",
    "        if len(self.episode_rewards)%5000 == 0 and not self.test_flag:\n",
    "            self.write_flag = True\n",
    "            out_directory = \"data/video/tt.video.\"+format(len(self.episode_rewards)/5000,\"06\")+\".mp4\"\n",
    "\n",
    "        if self.test_flag:\n",
    "            self.write_flag = True\n",
    "            out_directory = \"data/video_test/tt.video.\"+format(len(self.episode_rewards),\"06\")+\".mp4\"\n",
    "\n",
    "        if self.write_flag:\n",
    "            codec = cv2.VideoWriter_fourcc(*'H264')\n",
    "            fps = 10\n",
    "            self.video = cv2.VideoWriter(out_directory, codec, fps, (simulator[\"width\"]*debug_scale,simulator[\"height\"]*debug_scale))\n",
    "\n",
    "        num_walls = int((max_walls+1)*random.random())\n",
    "        # walls_sampled = random.sample(walls_samples, num_walls)\n",
    "        rand_direction = random.random()\n",
    "        if rand_direction >= 0.666:\n",
    "            walls_sampled = [[random.random()+0.7,-10*random.random()-20],[-random.random()-0.2,-10*random.random()-20],\\\n",
    "                        [10*random.random()+20,0.5*random.random()+0.4],[-10*random.random()-20,-0.5*random.random()-0.4]]\n",
    "        elif rand_direction >= 0.333:\n",
    "            walls_sampled = [[random.random()+0.7,10*random.random()+20],[-random.random()-0.2,10*random.random()+20],\\\n",
    "                        [-10*random.random()-20,0.5*random.random()+0.4],[10*random.random()+20,-0.5*random.random()-0.4]]\n",
    "        else:\n",
    "            walls_sampled = []\n",
    "\n",
    "        obstacles_temp = []\n",
    "        for wall in walls_sampled:\n",
    "            if abs(wall[1]) >= abs(wall[0]):\n",
    "                point_start = -2.0*map_param[\"center\"]\n",
    "                point_end = 2.0*map_param[\"center\"]\n",
    "                unit = (point_end-point_start)/200\n",
    "\n",
    "                for i in range(200):\n",
    "                    cy = (point_start + unit*i)\n",
    "                    cx = (wall[0]*(map_param[\"center\"]-(cy/wall[1])))\n",
    "                    obstacles_temp.append([cx,cy])\n",
    "            else:\n",
    "                point_start = -1.0*map_param[\"center\"]\n",
    "                point_end = 3.0*map_param[\"center\"]\n",
    "                unit = (point_end-point_start)/200\n",
    "\n",
    "                for i in range(200):\n",
    "                    cx = (point_start + unit*i)\n",
    "                    cy = (wall[1]*(map_param[\"center\"]-(cx/wall[0])))\n",
    "                    obstacles_temp.append([cx,cy])\n",
    "\n",
    "        for obstacle in obstacles_temp:\n",
    "            cx = obstacle[0]\n",
    "            cy = obstacle[1]\n",
    "            insert = True\n",
    "            for wall in walls_sampled:\n",
    "                if cx/wall[0] + cy/wall[1] > map_param[\"center\"]:\n",
    "                    insert = False\n",
    "            if insert:\n",
    "                self.obstacles.append([cx,cy])\n",
    "\n",
    "        for i in range(max_balls):\n",
    "            cx = int(1.0*random.random()*(map_param[\"height\"]-2*trans_scale)+2*trans_scale)\n",
    "            cy = int(1.0*random.random()*map_param[\"width\"]) - map_param[\"center\"]\n",
    "            insert = True\n",
    "            for wall in walls_sampled:\n",
    "                if cx/wall[0] + cy/wall[1] >= map_param[\"center\"]:\n",
    "                    insert = False\n",
    "            if insert:\n",
    "                self.balls.append([cx,cy])\n",
    "\n",
    "        ## For Test - Put every ball on a single horizontal line\n",
    "        # for i in range(max_balls):\n",
    "        #     cx = int(0.3*(map_param[\"height\"]-2*trans_scale)+2*trans_scale)\n",
    "        #     cy = int(0.4*(int(1.0*i/max_balls*map_param[\"width\"]) - map_param[\"center\"]))\n",
    "        #     insert = True\n",
    "        #     for wall in walls_sampled:\n",
    "        #         if cx/wall[0] + cy/wall[1] >= map_param[\"center\"]:\n",
    "        #             insert = False\n",
    "        #     if insert:\n",
    "        #         self.balls.append([cx,cy])\n",
    "        #########################################################################################\n",
    "\n",
    "        self.frame, self.frame_gray = self.draw_state()\n",
    "\n",
    "        if self.mlp_flag:\n",
    "            return self.frame\n",
    "        else:\n",
    "            return self.frame_gray\n",
    "\n",
    "    def check_window_state(self, cx, cy):\n",
    "        inscreen = True\n",
    "        if cx < 0 or cx >= simulator[\"width\"]:\n",
    "            inscreen = False\n",
    "        if cy < 0 or cy >= simulator[\"height\"]:\n",
    "            inscreen = False\n",
    "        return inscreen\n",
    "\n",
    "    def draw_debug_frame(self, frame):\n",
    "        frame_debug = np.zeros((simulator[\"height\"]*debug_scale,simulator[\"width\"]*debug_scale,3), np.uint8)\n",
    "        for i in range(simulator[\"width\"]):\n",
    "            for j in range(simulator[\"height\"]):\n",
    "                if frame[i][j] == map_param[\"Map.data.obstacle\"]:\n",
    "                    cv2.rectangle(frame_debug,(i*debug_scale,j*debug_scale),((i+1)*debug_scale-1,(j+1)*debug_scale-1),(255,255,0),-1)\n",
    "                if frame[i][j] == map_param[\"Map.data.ball\"]:\n",
    "                    cv2.rectangle(frame_debug,(i*debug_scale,j*debug_scale),((i+1)*debug_scale-1,(j+1)*debug_scale-1),(0,255,0),-1)\n",
    "\n",
    "        cv2.rectangle(frame_debug,(simulator[\"center\"]*debug_scale-1,(simulator[\"height\"]-1)*debug_scale+1),\\\n",
    "                    ((simulator[\"center\"]+1)*debug_scale,simulator[\"height\"]*debug_scale-1),(255,0,0),-1)\n",
    "\n",
    "        for i in range(1,simulator[\"width\"]):\n",
    "            cv2.line(frame_debug,(i*debug_scale,0),(i*debug_scale,simulator[\"height\"]*debug_scale-1),(128,128,128),1)\n",
    "            cv2.line(frame_debug,(0,i*debug_scale),(simulator[\"width\"]*debug_scale-1,i*debug_scale),(128,128,128),1)\n",
    "\n",
    "        cv2.line(frame_debug,((simulator[\"center\"]+ball_blind_bias)*debug_scale,simulator[\"height\"]*debug_scale-1),\\\n",
    "                            (simulator[\"width\"]*debug_scale-1,(simulator[\"height\"]-int(ball_blind_ratio*(simulator[\"center\"]-1-ball_blind_bias)))*debug_scale),(128,128,128),1)\n",
    "        cv2.line(frame_debug,((simulator[\"center\"]-ball_blind_bias+1)*debug_scale,simulator[\"height\"]*debug_scale-1),\\\n",
    "                            (0,(simulator[\"height\"]-int(ball_blind_ratio*(simulator[\"center\"]-1-ball_blind_bias)))*debug_scale),(128,128,128),1)\n",
    "\n",
    "        cv2.rectangle(frame_debug,((simulator[\"center\"]-2)*debug_scale-1,(simulator[\"height\"]-2)*debug_scale+1),\\\n",
    "                    ((simulator[\"center\"]+3)*debug_scale,simulator[\"height\"]*debug_scale-1),(0,0,255),2)\n",
    "\n",
    "        cv2.putText(frame_debug,\"Score \"+str(self.score), (int(simulator[\"width\"]*debug_scale*0.65),int(simulator[\"width\"]*debug_scale*0.05)), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (255,255,255))\n",
    "        cv2.putText(frame_debug,\"Step \"+str(self.iter), (int(simulator[\"width\"]*debug_scale*0.05),int(simulator[\"width\"]*debug_scale*0.05)), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (255,255,255))\n",
    "\n",
    "        return frame_debug\n",
    "\n",
    "    def draw_state(self):\n",
    "        frame = np.zeros((simulator[\"height\"],simulator[\"width\"],1), np.uint8)\n",
    "        frame_gray = np.zeros((simulator[\"height\"]*debug_scale_gray,simulator[\"width\"]*debug_scale_gray,1), np.uint8)\n",
    "\n",
    "        for obstacle in self.obstacles:\n",
    "            cx = simulator[\"center\"] - int(round(1.0*obstacle[1]/trans_scale))\n",
    "            cy = simulator[\"height\"] - 1 - int(round(1.0*obstacle[0]/trans_scale))\n",
    "            if self.check_window_state(cx, cy):\n",
    "                frame[cx][cy] = map_param[\"Map.data.obstacle\"]\n",
    "        for ball in self.balls:\n",
    "            if self.state_blink == False or random.random() > (0.3 + ball[0]/3.0/map_param[\"center\"]):\n",
    "                if ball[0] >= int(ball_blind_ratio*(abs(1.0*ball[1])-ball_blind_bias)):\n",
    "                    ball_x = ball[0]\n",
    "                    ball_y = ball[1]\n",
    "                    if self.state_inaccurate:\n",
    "                        ball_x = ball_x + random.random()*map_param[\"center\"]*(0.1*ball_x*ball_x/map_param[\"center\"]/map_param[\"center\"] - 0.05)\n",
    "                        ball_y = ball_y + random.random()*map_param[\"center\"]*(0.1*ball_x*ball_x/map_param[\"center\"]/map_param[\"center\"] - 0.05)\n",
    "\n",
    "                    cx = simulator[\"center\"] - int(round(1.0*ball_y/trans_scale))\n",
    "                    cy = simulator[\"height\"] - 1 - int(round(1.0*ball_x/trans_scale))\n",
    "                    if self.check_window_state(cx, cy):\n",
    "                        frame[cx][cy] = map_param[\"Map.data.ball\"]\n",
    "        frame[simulator[\"center\"]][simulator[\"height\"]-1] = 255\n",
    "\n",
    "        if not self.mlp_flag:\n",
    "            gray_color = {\"ball\":255, \"wall\":100, \"robot\":200, \"robot_padding\":150}\n",
    "            for i in range(simulator[\"width\"]):\n",
    "                for j in range(simulator[\"height\"]):\n",
    "                    if frame[i][j] == map_param[\"Map.data.obstacle\"]:\n",
    "                        cv2.rectangle(frame_gray,(i*debug_scale_gray,j*debug_scale_gray),((i+1)*debug_scale_gray-1,(j+1)*debug_scale_gray-1),gray_color[\"wall\"],-1)\n",
    "                    if frame[i][j] == map_param[\"Map.data.ball\"]:\n",
    "                        cv2.rectangle(frame_gray,(i*debug_scale_gray,j*debug_scale_gray),((i+1)*debug_scale_gray-1,(j+1)*debug_scale_gray-1),gray_color[\"ball\"],-1)\n",
    "\n",
    "            cv2.rectangle(frame_gray,((simulator[\"center\"]-2)*debug_scale_gray-1,(simulator[\"height\"]-2)*debug_scale_gray+1),\\\n",
    "                        ((simulator[\"center\"]+3)*debug_scale_gray,simulator[\"height\"]*debug_scale_gray-1),gray_color[\"robot_padding\"],-1)\n",
    "            cv2.rectangle(frame_gray,(simulator[\"center\"]*debug_scale_gray-1,(simulator[\"height\"]-1)*debug_scale_gray+1),\\\n",
    "                        ((simulator[\"center\"]+1)*debug_scale_gray,simulator[\"height\"]*debug_scale_gray-1),gray_color[\"robot\"],-1)\n",
    "\n",
    "        return frame, frame_gray\n",
    "\n",
    "    def get_reward(self, action):\n",
    "        reward = 0\n",
    "        balls_temp = []\n",
    "        for i, ball in enumerate(self.balls):\n",
    "            cx = int(round(1.0*ball[0]/trans_scale))\n",
    "            cy = int(round(abs(1.0*ball[1]/trans_scale)))\n",
    "            if  cx < reward_region_x and cx >= 0 and ball[0] >= int(ball_blind_ratio*(abs(1.0*ball[1])-ball_blind_bias)):\n",
    "                if cy <= reward_region_y[0]:\n",
    "                    reward = reward + 3\n",
    "                elif cy <= reward_region_y[1]:\n",
    "                    reward = reward + 2\n",
    "                elif cy <= reward_region_y[2]:\n",
    "                    reward = reward + 1\n",
    "                    if len(self.balls_prev) > 0:\n",
    "                        if int(round(1.0*self.balls_prev[i][0]/trans_scale)) < reward_region_x:\n",
    "                            reward = reward - 2\n",
    "                else:\n",
    "                    balls_temp.append(ball)\n",
    "            else:\n",
    "                balls_temp.append(ball)\n",
    "\n",
    "        balls_inscreen = []\n",
    "        for ball in balls_temp:\n",
    "            if ball[0] >= ball_blind_ratio * (abs(1.0*ball[1]) - ball_blind_bias)\\\n",
    "                and abs(1.0*ball[1]) <= map_param[\"center\"] and abs(1.0*ball[0]) < map_param[\"height\"]:\n",
    "                balls_inscreen.append(ball)\n",
    "\n",
    "        self.balls = balls_temp\n",
    "        if self.debug_flag:\n",
    "            print(\"balls length : \"+str(len(balls_temp))+\"  score : \"+str(self.score)+\"  screen_flag : \"+str(self.ball_inscreen_flag))\n",
    "\n",
    "        if action in range(10):\n",
    "            if len(balls_inscreen) == 0:\n",
    "                self.ball_inscreen_flag = self.ball_inscreen_flag + 1\n",
    "            else:\n",
    "                self.ball_inscreen_flag = 0\n",
    "\n",
    "        if len(balls_temp) == 0 or self.iter > max_iter or self.ball_inscreen_flag >= 10:\n",
    "            self.done = True\n",
    "\n",
    "        if self.done:\n",
    "            self.episode_rewards.append(self.score)\n",
    "            if self.write_flag:\n",
    "                self.video.release()\n",
    "                print(\"video saved\")\n",
    "\n",
    "        if action == -1:\n",
    "            return -1\n",
    "        else:\n",
    "            return reward\n",
    "\n",
    "    def step(self, action):\n",
    "        if action in range(10):\n",
    "            self.iter = self.iter + 1\n",
    "\n",
    "        del_x, del_y, rot = 0, 0, 0\n",
    "\n",
    "        if action == 0: # forward\n",
    "            del_x, del_y = -1, 0\n",
    "        elif action == 1: # forward right\n",
    "            del_x, del_y = -1, 1\n",
    "        elif action == 2: # right\n",
    "            del_x, del_y = 0, 1\n",
    "        elif action == 3: # backward right\n",
    "            del_x, del_y = 1, 1\n",
    "        elif action == 4: # backward\n",
    "            del_x, del_y = 1, 0\n",
    "        elif action == 5: # bacward left\n",
    "            del_x, del_y = 1, -1\n",
    "        elif action == 6: # left\n",
    "            del_x, del_y = 0, -1\n",
    "        elif action == 7: # forward left\n",
    "            del_x, del_y = -1, -1\n",
    "        elif action == 8: # turn left\n",
    "            rot = -1\n",
    "        elif action == 9: # turn right\n",
    "            rot = 1\n",
    "        else:\n",
    "            del_x, del_y, rot_x = 0, 0, 0\n",
    "\n",
    "        balls_temp = []\n",
    "        obstacles_temp = []\n",
    "\n",
    "        del_x = del_x * trans_scale\n",
    "        del_y = del_y * trans_scale\n",
    "\n",
    "\n",
    "        # Update the positions of balls and obstacles\n",
    "        if len(self.balls) > 0:\n",
    "            balls_temp = np.add(self.balls, [del_x,del_y])\n",
    "\n",
    "        if len(self.obstacles) > 0:\n",
    "            obstacles_temp = np.add(self.obstacles, [del_x,del_y])\n",
    "\n",
    "        if action == 8 or action == 9:\n",
    "            if len(self.obstacles) > 0 and len(balls_temp) > 0:\n",
    "                points = np.concatenate((balls_temp, obstacles_temp))\n",
    "            else:\n",
    "                points = np.array(balls_temp)\n",
    "\n",
    "            if points.size > 0:\n",
    "                points = points.reshape(-1,2)\n",
    "                theta = rot_scale*rot*np.pi/180\n",
    "                theta_0 = np.arctan2(points.T[1],points.T[0])\n",
    "\n",
    "                ball_dist = np.linalg.norm(points, axis=1)\n",
    "                rot_delta_unit_x = np.subtract(np.cos(theta_0), np.cos(np.add(theta_0,theta)))\n",
    "                rot_delta_unit_y = np.subtract(np.sin(theta_0), np.sin(np.add(theta_0,theta)))\n",
    "                rot_delta_unit = np.concatenate((rot_delta_unit_x.reshape(-1,1),rot_delta_unit_y.reshape(-1,1)),axis=1)\n",
    "                ball_dist = np.concatenate((ball_dist.reshape(-1,1),ball_dist.reshape(-1,1)),axis=1)\n",
    "                rot_delta = np.multiply(ball_dist, rot_delta_unit)\n",
    "                points = np.subtract(points, rot_delta)\n",
    "\n",
    "                balls_temp = points[0:len(self.balls)]\n",
    "                obstacles_temp = points[len(self.balls):]\n",
    "\n",
    "        # Check collision\n",
    "        enable_move = True\n",
    "        for obstacle in obstacles_temp:\n",
    "            # if int(abs(1.0*obstacle[0]/trans_scale)) <= 0 and int(abs(1.0*obstacle[1]/trans_scale)) <= 0:\n",
    "            if abs(1.0*obstacle[0]) < 2.0 and abs(1.0*obstacle[1]) < 2.0:\n",
    "                enable_move = False\n",
    "\n",
    "        # Update observation state and calculate reward\n",
    "        reward = 0\n",
    "        if enable_move:\n",
    "            self.balls = balls_temp\n",
    "            reward = self.get_reward(action)\n",
    "            self.obstacles = obstacles_temp\n",
    "            self.frame, self.frame_gray = self.draw_state()\n",
    "            self.balls_prev = self.balls\n",
    "        else:\n",
    "            reward = self.get_reward(-1)\n",
    "\n",
    "        self.score = self.score + reward\n",
    "\n",
    "        # Draw debug frame to record video\n",
    "        if self.write_flag:\n",
    "            frame_debug = self.draw_debug_frame(self.frame)\n",
    "            self.video.write(frame_debug)\n",
    "\n",
    "        # Draw debug frame to display debug map\n",
    "        if self.debug_flag:\n",
    "            frame_debug = self.draw_debug_frame(self.frame)\n",
    "            if not is_ipython:\n",
    "                cv2.imshow(\"frame_debug\", frame_debug)\n",
    "                cv2.imshow(\"frame_debug_gray\", self.frame_gray)\n",
    "            else:\n",
    "                plt.imshow(cv2.cvtColor(frame_debug,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if self.mlp_flag:\n",
    "            return self.frame, reward, self.done\n",
    "        else:\n",
    "            return self.frame_gray, reward, self.done\n",
    "\n",
    "    def render(self):\n",
    "        frame_debug = self.draw_debug_frame(self.frame)\n",
    "        return frame_debug\n",
    "\n",
    "    def get_total_steps(self):\n",
    "        return self.iter\n",
    "\n",
    "    def get_episode_rewards(self):\n",
    "        return self.episode_rewards\n",
    "\n",
    "    def action_space_sample(self):\n",
    "        index = int(1.0*random.random()*10)\n",
    "        return self.action_space[index]\n",
    "\n",
    "\n",
    "env = TTbotGym(debug_flag=False, mlp_flag=False, test_flag=False, state_blink=True, state_inaccurate=True)\n",
    "env.reset()\n",
    "plt.figure(figsize = (7,7))\n",
    "plt.imshow(cv2.cvtColor(env.render(),cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Replay Memory & DQN model & Epsilon-greedy function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TTbotGym(debug_flag=False, mlp_flag=False, test_flag=False, state_blink=True, state_inaccurate=True)\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.linear1 = nn.Linear(2592,448)\n",
    "        self.linear2 = nn.Linear(448, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.linear1(x.view(x.size(0), -1)))\n",
    "        x = F.softmax(self.linear2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "policy_net = DQN().to(device)\n",
    "target_net = DQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(1000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(10)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 46 running\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-292d61558167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Perform one step of the optimization (on the target network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b5d49b7e7b58>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Optimize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.5.5/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.5.5/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.figure(figsize = (7,7))\n",
    "img = plt.imshow(env.render())\n",
    "\n",
    "num_episodes = 50\n",
    "ep_monitor_rate = 10\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    ep_monitor_flag = False\n",
    "    if i_episode % ep_monitor_rate == 0:\n",
    "        ep_monitor_flag = True\n",
    "\n",
    "    # Initialize the environment and state\n",
    "    display.clear_output(wait=True)\n",
    "    print(\"episode %d running\"%(i_episode+1))\n",
    "    \n",
    "    state = env.reset()\n",
    "    state = torch.from_numpy(state.reshape(-1,93,93)).unsqueeze(0).to(device).type('torch.FloatTensor')\n",
    "    \n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        next_state, reward, done = env.step(action.item())\n",
    "        \n",
    "        next_state = torch.from_numpy(next_state.reshape(-1,93,93)).unsqueeze(0).to(device).type('torch.FloatTensor')\n",
    "        reward = torch.tensor([reward], device=device).type('torch.FloatTensor')\n",
    "        \n",
    "        if ep_monitor_flag:\n",
    "            img.set_data(cv2.cvtColor(env.render(),cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if is_ipython:\n",
    "            if ep_monitor_flag:\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(plt.gcf())\n",
    "\n",
    "        if not done:\n",
    "            next_state = state\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "\n",
    "        if done:\n",
    "            writer.add_scalar('data/TTbot/DQN/episode_durations', env.score, i_episode)\n",
    "            break\n",
    "\n",
    "    # Update the target network\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.close()\n",
    "writer.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
